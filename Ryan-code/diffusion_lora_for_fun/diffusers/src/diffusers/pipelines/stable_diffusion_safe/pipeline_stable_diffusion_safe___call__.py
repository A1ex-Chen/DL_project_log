@torch.no_grad()
def __call__(self, prompt: Union[str, List[str]], height: Optional[int]=
    None, width: Optional[int]=None, num_inference_steps: int=50,
    guidance_scale: float=7.5, negative_prompt: Optional[Union[str, List[
    str]]]=None, num_images_per_prompt: Optional[int]=1, eta: float=0.0,
    generator: Optional[Union[torch.Generator, List[torch.Generator]]]=None,
    latents: Optional[torch.Tensor]=None, ip_adapter_image: Optional[
    PipelineImageInput]=None, output_type: Optional[str]='pil', return_dict:
    bool=True, callback: Optional[Callable[[int, int, torch.Tensor], None]]
    =None, callback_steps: int=1, sld_guidance_scale: Optional[float]=1000,
    sld_warmup_steps: Optional[int]=10, sld_threshold: Optional[float]=0.01,
    sld_momentum_scale: Optional[float]=0.3, sld_mom_beta: Optional[float]=0.4
    ):
    """
        The call function to the pipeline for generation.

        Args:
            prompt (`str` or `List[str]`):
                The prompt or prompts to guide image generation. If not defined, you need to pass `prompt_embeds`.
            height (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`):
                The height in pixels of the generated image.
            width (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`):
                The width in pixels of the generated image.
            num_inference_steps (`int`, *optional*, defaults to 50):
                The number of denoising steps. More denoising steps usually lead to a higher quality image at the
                expense of slower inference.
            guidance_scale (`float`, *optional*, defaults to 7.5):
                A higher guidance scale value encourages the model to generate images closely linked to the text
                `prompt` at the expense of lower image quality. Guidance scale is enabled when `guidance_scale > 1`.
            negative_prompt (`str` or `List[str]`, *optional*):
                The prompt or prompts to guide what to not include in image generation. If not defined, you need to
                pass `negative_prompt_embeds` instead. Ignored when not using guidance (`guidance_scale < 1`).
            num_images_per_prompt (`int`, *optional*, defaults to 1):
                The number of images to generate per prompt.
            eta (`float`, *optional*, defaults to 0.0):
                Corresponds to parameter eta (Î·) from the [DDIM](https://arxiv.org/abs/2010.02502) paper. Only applies
                to the [`~schedulers.DDIMScheduler`], and is ignored in other schedulers.
            generator (`torch.Generator` or `List[torch.Generator]`, *optional*):
                A [`torch.Generator`](https://pytorch.org/docs/stable/generated/torch.Generator.html) to make
                generation deterministic.
            latents (`torch.Tensor`, *optional*):
                Pre-generated noisy latents sampled from a Gaussian distribution, to be used as inputs for image
                generation. Can be used to tweak the same generation with different prompts. If not provided, a latents
                tensor is generated by sampling using the supplied random `generator`.
            ip_adapter_image: (`PipelineImageInput`, *optional*):
                Optional image input to work with IP Adapters.
            output_type (`str`, *optional*, defaults to `"pil"`):
                The output format of the generated image. Choose between `PIL.Image` or `np.array`.
            return_dict (`bool`, *optional*, defaults to `True`):
                Whether or not to return a [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] instead of a
                plain tuple.
            callback (`Callable`, *optional*):
                A function that calls every `callback_steps` steps during inference. The function is called with the
                following arguments: `callback(step: int, timestep: int, latents: torch.Tensor)`.
            callback_steps (`int`, *optional*, defaults to 1):
                The frequency at which the `callback` function is called. If not specified, the callback is called at
                every step.
            sld_guidance_scale (`float`, *optional*, defaults to 1000):
                If `sld_guidance_scale < 1`, safety guidance is disabled.
            sld_warmup_steps (`int`, *optional*, defaults to 10):
                Number of warmup steps for safety guidance. SLD is only be applied for diffusion steps greater than
                `sld_warmup_steps`.
            sld_threshold (`float`, *optional*, defaults to 0.01):
                Threshold that separates the hyperplane between appropriate and inappropriate images.
            sld_momentum_scale (`float`, *optional*, defaults to 0.3):
                Scale of the SLD momentum to be added to the safety guidance at each diffusion step. If set to 0.0,
                momentum is disabled. Momentum is built up during warmup for diffusion steps smaller than
                `sld_warmup_steps`.
            sld_mom_beta (`float`, *optional*, defaults to 0.4):
                Defines how safety guidance momentum builds up. `sld_mom_beta` indicates how much of the previous
                momentum is kept. Momentum is built up during warmup for diffusion steps smaller than
                `sld_warmup_steps`.

        Returns:
            [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] or `tuple`:
                If `return_dict` is `True`, [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] is returned,
                otherwise a `tuple` is returned where the first element is a list with the generated images and the
                second element is a list of `bool`s indicating whether the corresponding generated image contains
                "not-safe-for-work" (nsfw) content.

        Examples:

        ```py
        import torch
        from diffusers import StableDiffusionPipelineSafe
        from diffusers.pipelines.stable_diffusion_safe import SafetyConfig

        pipeline = StableDiffusionPipelineSafe.from_pretrained(
            "AIML-TUDA/stable-diffusion-safe", torch_dtype=torch.float16
        ).to("cuda")
        prompt = "the four horsewomen of the apocalypse, painting by tom of finland, gaston bussiere, craig mullins, j. c. leyendecker"
        image = pipeline(prompt=prompt, **SafetyConfig.MEDIUM).images[0]
        ```
        """
    height = height or self.unet.config.sample_size * self.vae_scale_factor
    width = width or self.unet.config.sample_size * self.vae_scale_factor
    self.check_inputs(prompt, height, width, callback_steps)
    batch_size = 1 if isinstance(prompt, str) else len(prompt)
    device = self._execution_device
    do_classifier_free_guidance = guidance_scale > 1.0
    enable_safety_guidance = (sld_guidance_scale > 1.0 and
        do_classifier_free_guidance)
    if not enable_safety_guidance:
        warnings.warn('Safety checker disabled!')
    if ip_adapter_image is not None:
        output_hidden_state = False if isinstance(self.unet.
            encoder_hid_proj, ImageProjection) else True
        image_embeds, negative_image_embeds = self.encode_image(
            ip_adapter_image, device, num_images_per_prompt,
            output_hidden_state)
        if do_classifier_free_guidance:
            if enable_safety_guidance:
                image_embeds = torch.cat([negative_image_embeds,
                    image_embeds, image_embeds])
            else:
                image_embeds = torch.cat([negative_image_embeds, image_embeds])
    prompt_embeds = self._encode_prompt(prompt, device,
        num_images_per_prompt, do_classifier_free_guidance, negative_prompt,
        enable_safety_guidance)
    self.scheduler.set_timesteps(num_inference_steps, device=device)
    timesteps = self.scheduler.timesteps
    num_channels_latents = self.unet.config.in_channels
    latents = self.prepare_latents(batch_size * num_images_per_prompt,
        num_channels_latents, height, width, prompt_embeds.dtype, device,
        generator, latents)
    extra_step_kwargs = self.prepare_extra_step_kwargs(generator, eta)
    added_cond_kwargs = {'image_embeds': image_embeds
        } if ip_adapter_image is not None else None
    safety_momentum = None
    num_warmup_steps = len(timesteps
        ) - num_inference_steps * self.scheduler.order
    with self.progress_bar(total=num_inference_steps) as progress_bar:
        for i, t in enumerate(timesteps):
            latent_model_input = torch.cat([latents] * (3 if
                enable_safety_guidance else 2)
                ) if do_classifier_free_guidance else latents
            latent_model_input = self.scheduler.scale_model_input(
                latent_model_input, t)
            noise_pred = self.unet(latent_model_input, t,
                encoder_hidden_states=prompt_embeds, added_cond_kwargs=
                added_cond_kwargs).sample
            if do_classifier_free_guidance:
                noise_pred_out = noise_pred.chunk(3 if
                    enable_safety_guidance else 2)
                noise_pred_uncond, noise_pred_text = noise_pred_out[0
                    ], noise_pred_out[1]
                noise_guidance = noise_pred_text - noise_pred_uncond
                if enable_safety_guidance:
                    if safety_momentum is None:
                        safety_momentum = torch.zeros_like(noise_guidance)
                    noise_pred_safety_concept = noise_pred_out[2]
                    scale = torch.clamp(torch.abs(noise_pred_text -
                        noise_pred_safety_concept) * sld_guidance_scale,
                        max=1.0)
                    safety_concept_scale = torch.where(noise_pred_text -
                        noise_pred_safety_concept >= sld_threshold, torch.
                        zeros_like(scale), scale)
                    noise_guidance_safety = torch.mul(
                        noise_pred_safety_concept - noise_pred_uncond,
                        safety_concept_scale)
                    noise_guidance_safety = (noise_guidance_safety + 
                        sld_momentum_scale * safety_momentum)
                    safety_momentum = sld_mom_beta * safety_momentum + (1 -
                        sld_mom_beta) * noise_guidance_safety
                    if i >= sld_warmup_steps:
                        noise_guidance = noise_guidance - noise_guidance_safety
                noise_pred = (noise_pred_uncond + guidance_scale *
                    noise_guidance)
            latents = self.scheduler.step(noise_pred, t, latents, **
                extra_step_kwargs).prev_sample
            if i == len(timesteps) - 1 or i + 1 > num_warmup_steps and (i + 1
                ) % self.scheduler.order == 0:
                progress_bar.update()
                if callback is not None and i % callback_steps == 0:
                    step_idx = i // getattr(self.scheduler, 'order', 1)
                    callback(step_idx, t, latents)
    image = self.decode_latents(latents)
    image, has_nsfw_concept, flagged_images = self.run_safety_checker(image,
        device, prompt_embeds.dtype, enable_safety_guidance)
    if output_type == 'pil':
        image = self.numpy_to_pil(image)
        if flagged_images is not None:
            flagged_images = self.numpy_to_pil(flagged_images)
    if not return_dict:
        return (image, has_nsfw_concept, self._safety_text_concept if
            enable_safety_guidance else None, flagged_images)
    return StableDiffusionSafePipelineOutput(images=image,
        nsfw_content_detected=has_nsfw_concept, applied_safety_concept=self
        ._safety_text_concept if enable_safety_guidance else None,
        unsafe_images=flagged_images)
